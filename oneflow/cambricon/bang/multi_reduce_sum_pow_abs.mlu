/*
Copyright 2020 The OneFlow Authors. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/
#include <cstring>
#include "oneflow/cambricon/bang/bang_internal.h"
#include "oneflow/cambricon/bang/bang_kernels.h"

namespace oneflow {

static constexpr int32_t nram_limit = 32;
static constexpr int32_t BATCH = 256;
static __mlu_shared__ char s_result[1024 * 4];

template<typename T>
__mlu_global__ void bang_multi_reduce_sum_pow_abs_kernel_internal(int64_t n,
                                                                  AddressList<BATCH> inputs_info,
                                                                  float p, T* workspace) {
  int32_t core_dim = taskDim / clusterDim;
  int32_t core_id = taskId % core_dim;

  int32_t nram_limit_bytes = nram_limit * sizeof(T);

  __nram__ T nram_input[nram_limit];
  __nram__ T nram_result[nram_limit];

  __bang_write_zero(nram_result, nram_limit);

  for (int64_t i = clusterId; i < n; i += clusterDim) {
    const T* input = static_cast<const T*>(inputs_info.address[i]);
    int64_t size = inputs_info.sizes[i];

    int64_t step = (size + core_dim - 1) / core_dim;
    int64_t start = step * core_id;
    int64_t end = start + step;
    if (end > size) { end = size; }
    int64_t length = start < end ? end - start : 0;
    int64_t nram_rest = (length & 0x1F);  // length % nram_limit2

    int64_t j = 0;
    for (; j < length - nram_limit + 1; j += nram_limit) {
      __memcpy_async(nram_input, input + start + j, nram_limit_bytes, GDRAM2NRAM);
      __sync_copy_dram_to_nram();
      if (p == 0.f) {
        __bang_ne_scalar(nram_input, nram_input, T(0), nram_limit);
      } else if (p == 1.f) {
        __bang_abs(nram_input, nram_input, nram_limit);
      } else if (p == 2.f) {
        __bang_square(nram_input, nram_input, nram_limit);
      } else {
        __bang_abs(nram_input, nram_input, nram_limit);
        for (int k = 0; k < nram_limit; ++k) { nram_input[k] = pow(nram_input[k], p); }
      }
      __bang_add(nram_result, nram_result, nram_input, nram_limit);
    }
    if (nram_rest > 0) {
      __memcpy_async(nram_input, input + start + j, nram_rest * sizeof(T), GDRAM2NRAM);
      __sync_copy_dram_to_nram();
      if (p == 0.f) {
        __bang_ne_scalar(nram_input, nram_input, T(0), nram_rest);
      } else if (p == 1.f) {
        __bang_abs(nram_input, nram_input, nram_rest);
      } else if (p == 2.f) {
        __bang_square(nram_input, nram_input, nram_rest);
      } else {
        __bang_abs(nram_input, nram_input, nram_rest);
        for (int k = 0; k < nram_rest; ++k) { nram_input[k] = pow(nram_input[k], p); }
      }
      __bang_add(nram_result, nram_result, nram_input, nram_rest);
    }
  }

  T* s_data = reinterpret_cast<T*>(s_result);
  int32_t offset = clusterId * core_dim;

#if (__BANG_ARCH__ >= 520)
  s_data[offset + core_id] = __bang_sum(nram_result, nram_limit);
#else
  T result = 0;
  for (int i = 0; i < nram_limit; ++i) { result += nram_result[i]; }
  s_data[offset + core_id] = result;
#endif

  __sync_cluster();

  if (clusterId < n && core_id == 0) {
    T result = s_data[offset];
    for (int i = 1; i < core_dim; ++i) { result += s_data[offset + i]; }
    workspace[clusterId] += result;
  }
}

template<typename T>
__mlu_global__ void bang_multi_reduce_sum_pow_abs_kernel_internal_final(int64_t n,
                                                                        const T* workspace,
                                                                        T* output) {
  int32_t nram_limit_bytes = nram_limit * sizeof(T);
  int32_t nram_rest = (n & 0x1F);  // n % nram_limit

  __nram__ T nram_input[nram_limit];
  __nram__ T nram_result[nram_limit];

  __bang_write_zero(nram_result, nram_limit);

  int i = 0;
  for (; i < n - nram_limit + 1; i += nram_limit) {
    __memcpy_async(nram_input, workspace + i, nram_limit_bytes, GDRAM2NRAM);
    __sync_copy_dram_to_nram();
    __bang_add(nram_result, nram_result, nram_input, nram_limit);
  }
  if (nram_rest > 0) {
    __memcpy_async(nram_input, workspace + i, nram_rest * sizeof(T), GDRAM2NRAM);
    __sync_copy_dram_to_nram();
    __bang_add(nram_result, nram_result, nram_input, nram_rest);
  }

#if (__BANG_ARCH__ >= 520)
  *output = __bang_sum(nram_result, nram_limit);
#else
  T result = 0;
  for (int i = 0; i < nram_limit; ++i) { result += nram_result[i]; }
  *output = result;
#endif
}

template<typename T>
void bang_multi_reduce_sum_pow_abs_kernel(BangHandle& handle, int64_t n, const T** inputs,
                                          const int64_t* sizes, T* output, float p, void* workspace,
                                          int64_t workspace_size) {
  if (n == 0) {
    cnrtMemsetAsync(output, 0, sizeof(T), handle.queue);
    return;
  }
  cnrtMemsetAsync(workspace, 0, workspace_size, handle.queue);

  // TODO(): check workspace_size == n * sizeof(T)
  T* workspace_ptr = static_cast<T*>(workspace);

  cnrtDim3_t dim = {handle.nclusters * handle.ncores_per_cluster, 1, 1};
  cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_UNION1;

  for (int64_t i = 0; i < n; i += BATCH) {
    int32_t num = (n - i) > BATCH ? BATCH : (n - i);
    AddressList<BATCH> inputs_info;
    memcpy(inputs_info.address, inputs + i, num * sizeof(void*));
    memcpy(inputs_info.sizes, sizes + i, num * sizeof(int64_t));

    bang_multi_reduce_sum_pow_abs_kernel_internal<<<dim, func_type, handle.queue>>>(
        num, inputs_info, p, workspace_ptr);
  }

  dim = {1, 1, 1};
  bang_multi_reduce_sum_pow_abs_kernel_internal_final<<<dim, CNRT_FUNC_TYPE_BLOCK, handle.queue>>>(
      n, workspace_ptr, output);
}

#define INSTANCE_BANG_MULTI_REDUCE_SUM_POW_ABS_KERNEL(T)                                          \
  template void bang_multi_reduce_sum_pow_abs_kernel<T>(                                          \
      BangHandle & handle, int64_t n, const T** inputs, const int64_t* sizes, T* output, float p, \
      void* workspace, int64_t workspace_size);

INSTANCE_BANG_MULTI_REDUCE_SUM_POW_ABS_KERNEL(float)

#undef INSTANCE_BANG_MULTI_REDUCE_SUM_POW_ABS_KERNEL

}  // namespace oneflow
