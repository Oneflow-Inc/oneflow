syntax = "proto2";
package oneflow;

import "oneflow/core/common/data_type.proto";
import "oneflow/core/job/dlnet_conf.proto";
import "oneflow/core/job/placement.proto";
import "oneflow/core/register/logical_blob_id.proto";
import "oneflow/core/register/op_blob_arg.proto";
import "oneflow/core/register/blob_desc.proto";
import "oneflow/core/operator/op_conf.proto";
import "oneflow/core/common/shape.proto";
import "oneflow/core/job/sbp_parallel.proto";

message TrainConf {
  required NormalModelUpdateOpUserConf model_update_conf = 3;
  repeated string loss_lbn = 6;
  optional int32 loss_scale_factor = 7 [default = 1];
  optional string train_step_lbn = 8;
  optional string primary_lr_lbn = 9;
  optional string secondary_lr_lbn = 10;

  required float primary_lr = 101;
  optional float secondary_lr = 102;
  optional float weight_l1 = 103 [default = 0];
  optional float bias_l1 = 104 [default = 0];
  optional float weight_l2 = 105 [default = 0];
  optional float bias_l2 = 106 [default = 0];
}

message PredictConf {
}

message SbpConf {
  map<string, SbpSignature> op_name2sbp_signature_conf = 1;
}

message ExperimentalRunConf {
  optional int64 piece_num_of_experiment_phase = 1 [default = -1];
  optional bool enable_experiment_run = 2 [default = false];
}

message JobConfigProto {
  required string job_name = 1;

  oneof job_type {
    TrainConf train_conf = 3;
    PredictConf predict_conf = 4;
  }
  optional int64 total_batch_num = 7 [default = 1];
  optional DataType default_data_type = 8 [default = kFloat]; // kFloat or kDouble
  optional int32 max_data_id_length = 9 [default = 0];
  oneof default_initialize_conf {
    InitializerConf default_initializer_conf = 10;
    string default_initialize_with_snapshot_path = 11;
  }

  optional ExperimentalRunConf exp_run_conf = 100;

  optional bool enable_cudnn = 200 [default = true];
  optional int64 cudnn_buf_limit_mbyte = 201 [default = 1024];  // 1GByte
  optional int32 cudnn_conv_force_fwd_algo = 202;
  optional int32 cudnn_conv_force_bwd_data_algo = 203;
  optional int32 cudnn_conv_force_bwd_filter_algo = 204;
  
  optional bool enable_reuse_mem = 300 [default = true];
  optional bool enable_inplace = 301 [default = true];
  optional bool enable_inplace_in_reduce_struct = 302 [default = true];

  optional bool enable_nccl = 400 [default = true];
  optional bool use_nccl_inter_node_communication = 401 [default = true];
  optional bool use_boxing_v2 = 402 [default = false];

  optional bool enable_all_reduce_group = 500 [default = true];
  optional int64 all_reduce_group_num = 501 [default = 8];
  // example:
  //   all_reduce_lazy_ratio = 0.5
  // It means that half of all_reduce nodes overlap with the forward pass of next batch
  optional float all_reduce_lazy_ratio = 502 [default = 0.5];
  optional int64 all_reduce_group_min_mbyte = 503 [default = 16];
  // example:
  //   total weight bytes is 1024M
  //   all_reduce_group_num = 8
  //   all_reduce_group_min_mbyte = 16
  //   all_reduce_group_size_warmup = 2
  // Each nodes' weight size are [16, 32, 64, 128, 128, 128, 128, 128, 128, 128, 16].
  // You can see the actual number of reduce group is slightly bigger than all_reduce_group_num.
  optional float all_reduce_group_size_warmup = 504 [default = 2];
  optional bool all_reduce_fp16 = 505 [default = true];
  optional bool enable_non_distributed_optimizer = 506 [default = false];
  optional int64 non_distributed_optimizer_group_size_mbyte = 507 [default = 100];
  optional bool disable_all_reduce_sequence = 508 [default = false];

  optional bool enable_true_half_config_when_conv = 600 [default = false];
  optional bool enable_float_compute_for_half_gemm = 601 [default = true];
  optional bool enable_auto_mixed_precision = 602 [default = false];

  optional int64 concurrency_width = 1000 [default = 128];
}

message OpTimeShape {
  optional ShapeProto in_blob_fastest_time_shape = 1;
  optional ShapeProto out_blob_time_shape = 2;
}

message ParallelBlobConf {
  required BlobDescProto logical_blob_desc_conf = 1;
  required ParallelConf parallel_conf = 2;
  required SbpParallel sbp_conf = 3;
  required OptInt64 batch_axis = 4;
}

message JobHelperConf {
  map<string, LogicalBlobIdPairs> tag2lbi_relations = 1;
  map<string, OpNameRelations> tag2op_name_relations = 2;
  map<string, OpTimeShape> op_name2op_time_shape = 3;
  map<string, BlobDescProto> lbn2logical_blob_desc = 4;
  map<string, OptInt64> lbn2batch_axis = 6;
  optional OpBlobArgPairs identical_sbp_oba_pairs = 7;
}

message Job {
  required DLNetConf net = 1;
  required Placement placement = 2;
  required JobConfigProto job_conf = 3;
  optional SbpConf sbp_conf = 4;
  optional JobHelperConf helper = 5;
}
