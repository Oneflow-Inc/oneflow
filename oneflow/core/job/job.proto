syntax = "proto2";
package oneflow;

import "oneflow/core/common/data_type.proto";
import "oneflow/core/job/dlnet_conf.proto";
import "oneflow/core/job/placement.proto";
import "oneflow/core/register/logical_blob_id.proto";
import "oneflow/core/register/op_blob_arg.proto";
import "oneflow/core/register/blob_desc.proto";
import "oneflow/core/operator/op_conf.proto";
import "oneflow/core/common/shape.proto";
import "oneflow/core/job/sbp_parallel.proto";

message TrainConf {
  required int64 batch_size = 1; // batch_size % piece_size = 0
  required NormalModelUpdateOpUserConf model_update_conf = 3;
  required int32 num_of_batches_in_snapshot = 5;
  repeated string loss_lbn = 6;
  optional int32 loss_scale_factor = 7 [default = 1];

  // default_initializer_conf here is now deprecated
  optional InitializerConf default_initializer_conf = 100;
  required float primary_lr = 101;
  optional float secondary_lr = 102 [default = -1];
  optional float weight_l1 = 103 [default = 0];
  optional float bias_l1 = 104 [default = 0];
  optional float weight_l2 = 105 [default = 0];
  optional float bias_l2 = 106 [default = 0];
  optional int64 piece_num_of_print_loss = 107 [default = -1];
  optional int64 piece_num_of_print_accuracy = 108 [default = -1];
}

message PredictConf {
}

message SbpConf {
  map<string, SbpSignature> op_name2sbp_signature_conf = 1;
}

message ExperimentalRunConf {
  optional int64 piece_num_of_experiment_phase = 1 [default = -1];
  optional bool enable_experiment_run = 2 [default = false];
}

message JobConfigProto {
  required string job_name = 1;
  repeated string arg_op_name = 2;

  oneof job_type {
    TrainConf train_conf = 3;
    PredictConf predict_conf = 4;
  }
  optional int64 piece_size = 5 [default = 1];
  required int32 data_part_num = 6; // piece_size % data_part_num = 0
  optional int64 total_batch_num = 7 [default = 1];
  optional DataType default_data_type = 8 [default = kFloat]; // kFloat or kDouble
  optional int32 max_data_id_length = 9 [default = 0];
  optional InitializerConf default_initializer_conf = 10;

  optional ExperimentalRunConf exp_run_conf = 100;

  optional bool enable_cudnn = 200 [default = true];
  optional int64 cudnn_buf_limit_mbyte = 201 [default = 1024];  // 1GByte

  optional bool enable_mem_sharing = 300 [default = true];
  optional bool enable_inplace = 301 [default = true];

  optional bool enable_nccl = 400 [default = true];
  optional bool use_nccl_inter_node_communication = 401 [default = false];

  optional int64 all_reduce_group_num = 500 [default = 8];
  // example:
  //   all_reduce_lazy_ratio = 0.5
  // It means that half of all_reduce nodes overlap with the forward pass of next batch
  optional float all_reduce_lazy_ratio = 600 [default = 0.5];
  optional int64 all_reduce_group_min_mbyte = 601 [default = 16];
  // example:
  //   total weight bytes is 1024M
  //   all_reduce_group_num = 8
  //   all_reduce_group_min_mbyte = 16
  //   all_reduce_group_size_warmup = 2
  // Each nodes' weight size are [16, 32, 64, 128, 128, 128, 128, 128, 128, 128, 16].
  // You can see the actual number of reduce group is slightly bigger than all_reduce_group_num.
  optional float all_reduce_group_size_warmup = 602 [default = 2];
  optional bool all_reduce_fp16 = 603 [default = true];
  optional bool enable_true_half_config_when_conv = 604 [default = false];
  optional bool enable_float_compute_for_half_gemm = 605 [default = true];
  optional bool enable_auto_mixed_precision = 606 [default = false];
  optional bool enable_cuda_ring_all_reduce = 608 [default = false];
  optional bool cuda_ring_all_reduce_enable_p2p = 609 [default = false];

  optional int64 concurrency_width = 1000 [default = 128];
}

message OpTimeShape {
  optional ShapeProto in_blob_fastest_time_shape = 1;
  optional ShapeProto out_blob_time_shape = 2;
}

message ParallelBlobConf {
  required BlobDescProto logical_blob_desc_conf = 1;
  required ParallelConf parallel_conf = 2;
  required SbpParallel sbp_conf = 3;
  required bool has_batch_dim = 4;
}

message JobHelperConf {
  map<string, LogicalBlobIdPairs> tag2lbi_relations = 1;
  map<string, OpNameRelations> tag2op_name_relations = 2;
  map<string, OpTimeShape> op_name2op_time_shape = 3;
  map<string, BlobDescProto> lbn2logical_blob_desc = 4;
  repeated LogicalBlobId batch_dim_lbis = 6;
  optional OpBlobArgPairs identical_sbp_oba_pairs = 7;
}

message Job {
  required DLNetConf net = 1;
  required Placement placement = 2;
  required JobConfigProto job_conf = 3;
  optional SbpConf sbp_conf = 4;
  optional JobHelperConf helper = 5;
}
